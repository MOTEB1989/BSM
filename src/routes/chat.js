import { Router } from "express";
import { runAgent } from "../runners/agentRunner.js";
import { runGPT } from "../services/gptService.js";
import { models } from "../config/models.js";
import { AppError } from "../utils/errors.js";
import { env } from "../config/env.js";
import logger from "../utils/logger.js";

const router = Router();

// Unified key-status endpoint â€” single source of truth
router.get("/key-status", (_req, res, next) => {
  try {
    const status = {
      openai: Boolean(models.openai?.default || models.openai?.bsm || models.openai?.bsu),
      anthropic: Boolean(models.anthropic?.default),
      perplexity: Boolean(models.perplexity?.default),
      google: Boolean(models.google?.default),
      azure: Boolean(models.azure?.default),
      groq: Boolean(models.groq?.default),
      cohere: Boolean(models.cohere?.default),
      mistral: Boolean(models.mistral?.default)
    };

    const activeCount = Object.values(status).filter(Boolean).length;

    const ui = {
      openai: status.openai ? "âœ… GPT-4 Ready" : "ğŸ”´ GPT-4 Offline",
      anthropic: status.anthropic ? "âœ… Claude Ready" : "ğŸ”´ Claude Offline",
      perplexity: status.perplexity ? "âœ… Perplexity Ready" : "ğŸ”´ Perplexity Offline",
      google: status.google ? "âœ… Gemini Ready" : "ğŸ”´ Gemini Offline",
      azure: status.azure ? "âœ… Azure OpenAI Ready" : "âš« Azure Offline",
      groq: status.groq ? "âœ… Groq Ready" : "âš« Groq Offline",
      cohere: status.cohere ? "âœ… Cohere Ready" : "âš« Cohere Offline",
      mistral: status.mistral ? "âœ… Mistral Ready" : "âš« Mistral Offline"
    };

    res.json({
      configured: status.openai,
      activeProviders: activeCount,
      timestamp: new Date().toISOString(),
      status,
      ui
    });
  } catch (err) {
    next(err);
  }
});

// Agent-based chat
router.post("/", async (req, res, next) => {
  try {
    const { agentId, input } = req.body;
    const result = await runAgent({ agentId, input });
    res.json({ output: result.output });
  } catch (err) {
    next(err);
  }
});

// Direct GPT chat (no agent required)
router.post("/direct", async (req, res, next) => {
  try {
    const { message, history = [], language = "ar", model: requestedModel = "gpt-4o-mini" } = req.body;

    if (!message || typeof message !== "string" || !message.trim()) {
      throw new AppError("Message is required", 400, "INVALID_INPUT");
    }

    if (message.length > env.maxAgentInputLength) {
      throw new AppError("Message too long", 400, "INPUT_TOO_LONG");
    }

    if (!Array.isArray(history)) {
      throw new AppError("History must be an array", 400, "INVALID_HISTORY");
    }

    if (!["ar", "en"].includes(language)) {
      throw new AppError("Unsupported language", 400, "INVALID_LANGUAGE");
    }

    const ALLOWED_MODELS = ["gpt-4o-mini", "gpt-4o", "perplexity"];
    const selectedModel = ALLOWED_MODELS.includes(requestedModel) ? requestedModel : "gpt-4o-mini";

    const systemPrompt = language === "ar"
      ? "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…Ù† Ù…Ù†ØµØ© LexBANK. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…Ù‡Ù†ÙŠ ÙˆÙ…ÙÙŠØ¯. Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆØ§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ©."
      : "You are a smart assistant from the LexBANK platform. Answer professionally and helpfully. Assist users with legal, technical, and administrative questions.";

    let result;

    if (selectedModel === "perplexity") {
      if (!models.perplexity?.default) {
        throw new AppError("Perplexity service is not configured", 503, "MISSING_API_KEY");
      }
      const { modelRouter } = await import("../config/modelRouter.js");
      const routed = await modelRouter.execute(
        { system: systemPrompt, user: message, messages: null },
        { requiresSearch: true, searchQuery: message, task: "chat_response", complexity: "medium" }
      );
      result = routed?.output || "";
    } else {
      const apiKey = models.openai?.bsm || models.openai?.default;
      if (!apiKey) {
        throw new AppError("AI service is not configured", 503, "MISSING_API_KEY");
      }

      const messages = [{ role: "system", content: systemPrompt }];
      const recentHistory = history.slice(-20);
      for (const msg of recentHistory) {
        if (msg && typeof msg === "object" && (msg.role === "user" || msg.role === "assistant")) {
          messages.push({ role: msg.role, content: String(msg.content).slice(0, env.maxAgentInputLength) });
        }
      }
      messages.push({ role: "user", content: message });

      result = await runGPT({
        model: selectedModel,
        apiKey,
        system: systemPrompt,
        user: message,
        messages
      });
    }

    const output = (result !== null && result !== undefined && result !== "")
      ? result
      : (language === "ar" ? "Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø¯." : "No response received.");

    res.json({ output, modelUsed: selectedModel });
  } catch (err) {
    next(err);
  }
});

export default router;
